{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Things to consider\n",
    "\n",
    "- The value of segmentation can be any number of points (>=3).\n",
    "\"bbox\": [min_x, min_y, w, h], \"segmentation\": [[x1, y1, x2, y2, x3, y3, x4, y4, x5, y5, ...]]\n",
    "- custom training script:\n",
    "```\n",
    "./tools/dist_train.sh configs/textdet/dbnet/dbnet_r18_fpnc_1200e_icdar2015.py dbnet 1\n",
    "\n",
    "python tools/train.py D:\\mmocr\\configs\\textdet\\dbnet\\initial_training_dbnet.py\n",
    "```\n",
    "- txt to lmdb converter: tools/data/utils/txt2lmdb.py\n",
    "- how to use my dataset: https://github.com/open-mmlab/mmocr/issues/229\n",
    "- Can't save best model automatically with DB Text Detection: https://github.com/open-mmlab/mmocr/issues/750"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assuming you set up the data pipeline properly (D:\\mmocr\\configs_base_\\det_datasets\\icdar2015.py for me) correlating to your preprocessed dataset (https://github.com/open-mmlab/mmocr/blob/main/docs/en/datasets/det.md), you should be able to train with a simple"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dataset için: configs/_base_/det_datasets => toy_data gibi manipule et.\n",
    "training config için: configs/dbnet/...custom.py gibi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "schedule ve epoch: /home/gsoykan20/Desktop/self_development/mmocr/configs/_base_/schedules/schedule_sgd_1200e.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "custom training dosyasında eval i değiştirirsen best save olayını daha iyi yaparsın:\n",
    "```\n",
    "evaluation = dict(\n",
    "    interval=1, metric=[\"hmean-iou\"], save_best=\"0_hmean-iou_hmean\", rule=\"greater\"\n",
    ") // for best saving\n",
    "checkpoint_config = dict(interval=2) // for saving regardless\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Annotation tool: LabelMe https://github.com/wkentaro/labelme"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# base model: DB_r50 olacak."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_config_path_ref = \"/home/gsoykan20/Desktop/self_development/mmocr/configs/textdet/dbnet/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom.py\"\n",
    "model_checkpoint_file = \"/home/gsoykan20/.cache/torch/hub/checkpoints/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20211025-9fe3b590.pth\"\n",
    "finetuned_model_checkpoint_file = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom_41train_10test/best_0_hmean-iou:hmean_epoch_9.pth\"\n",
    "finetuned_model_80_checkpoint_file = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom/best_0_hmean-iou:hmean_epoch_4.pth\"\n",
    "finetuned_model_100_checkpoint_file = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom_90train_10test/best_0_hmean-iou:hmean_epoch_5.pth\"\n",
    "\n",
    "finetuned_model_160_checkpoint_file = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom_140_20_adam6/best_0_hmean-iou:hmean_epoch_3.pth\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "2022-02-14 12:19:48,838 - mmocr - INFO - Environment info:\r\n",
      "------------------------------------------------------------\r\n",
      "sys.platform: linux\r\n",
      "Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]\r\n",
      "CUDA available: True\r\n",
      "GPU 0: Quadro RTX 3000\r\n",
      "CUDA_HOME: /usr/local/cuda\r\n",
      "NVCC: Build cuda_11.4.r11.4/compiler.30300941_0\r\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\n",
      "PyTorch: 1.6.0\r\n",
      "PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 7.3\r\n",
      "  - C++ Version: 201402\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 10.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n",
      "  - CuDNN 7.6.3\r\n",
      "  - Magma 2.5.2\r\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \r\n",
      "\r\n",
      "TorchVision: 0.7.0\r\n",
      "OpenCV: 4.5.4\r\n",
      "MMCV: 1.3.17\r\n",
      "MMCV Compiler: GCC 7.3\r\n",
      "MMCV CUDA Compiler: 10.1\r\n",
      "MMOCR: 0.4.1+1aae45b\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "2022-02-14 12:19:49,278 - mmocr - INFO - Distributed training: False\r\n",
      "2022-02-14 12:19:49,764 - mmocr - INFO - Config:\r\n",
      "checkpoint_config = dict(interval=10)\r\n",
      "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\r\n",
      "dist_params = dict(backend='nccl')\r\n",
      "log_level = 'INFO'\r\n",
      "load_from = 'checkpoints/textdet/dbnet/res50dcnv2_synthtext.pth'\r\n",
      "resume_from = None\r\n",
      "workflow = [('train', 1)]\r\n",
      "opencv_num_threads = 0\r\n",
      "mp_start_method = 'fork'\r\n",
      "optimizer = dict(type='SGD', lr=0.007, momentum=0.9, weight_decay=0.0001)\r\n",
      "optimizer_config = dict(grad_clip=None)\r\n",
      "lr_config = dict(policy='poly', power=0.9, min_lr=1e-07, by_epoch=True)\r\n",
      "total_epochs = 1200\r\n",
      "model = dict(\r\n",
      "    type='DBNet',\r\n",
      "    backbone=dict(\r\n",
      "        type='mmdet.ResNet',\r\n",
      "        depth=50,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(0, 1, 2, 3),\r\n",
      "        frozen_stages=-1,\r\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\r\n",
      "        norm_eval=False,\r\n",
      "        style='pytorch',\r\n",
      "        dcn=dict(type='DCNv2', deform_groups=1, fallback_on_stride=False),\r\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),\r\n",
      "        stage_with_dcn=(False, True, True, True)),\r\n",
      "    neck=dict(\r\n",
      "        type='FPNC', in_channels=[256, 512, 1024, 2048], lateral_channels=256),\r\n",
      "    bbox_head=dict(\r\n",
      "        type='DBHead',\r\n",
      "        in_channels=256,\r\n",
      "        loss=dict(type='DBLoss', alpha=5.0, beta=10.0, bbce_loss=True),\r\n",
      "        postprocessor=dict(type='DBPostprocessor', text_repr_type='quad')),\r\n",
      "    train_cfg=None,\r\n",
      "    test_cfg=None)\r\n",
      "root = 'tests/data/toy_dataset'\r\n",
      "train1 = dict(\r\n",
      "    type='TextDetDataset',\r\n",
      "    img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "    ann_file='tests/data/toy_dataset/instances_test.txt',\r\n",
      "    loader=dict(\r\n",
      "        type='HardDiskLoader',\r\n",
      "        repeat=4,\r\n",
      "        parser=dict(\r\n",
      "            type='LineJsonParser',\r\n",
      "            keys=['file_name', 'height', 'width', 'annotations'])),\r\n",
      "    pipeline=None,\r\n",
      "    test_mode=False)\r\n",
      "train2 = dict(\r\n",
      "    type='IcdarDataset',\r\n",
      "    ann_file='tests/data/toy_dataset/instances_test.json',\r\n",
      "    img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "    pipeline=None)\r\n",
      "test = dict(\r\n",
      "    type='TextDetDataset',\r\n",
      "    img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "    ann_file='tests/data/toy_dataset/instances_test.txt',\r\n",
      "    loader=dict(\r\n",
      "        type='HardDiskLoader',\r\n",
      "        repeat=1,\r\n",
      "        parser=dict(\r\n",
      "            type='LineJsonParser',\r\n",
      "            keys=['file_name', 'height', 'width', 'annotations'])),\r\n",
      "    pipeline=None,\r\n",
      "    test_mode=True)\r\n",
      "train_list = [\r\n",
      "    dict(\r\n",
      "        type='TextDetDataset',\r\n",
      "        img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "        ann_file='tests/data/toy_dataset/instances_test.txt',\r\n",
      "        loader=dict(\r\n",
      "            type='HardDiskLoader',\r\n",
      "            repeat=4,\r\n",
      "            parser=dict(\r\n",
      "                type='LineJsonParser',\r\n",
      "                keys=['file_name', 'height', 'width', 'annotations'])),\r\n",
      "        pipeline=None,\r\n",
      "        test_mode=False),\r\n",
      "    dict(\r\n",
      "        type='IcdarDataset',\r\n",
      "        ann_file='tests/data/toy_dataset/instances_test.json',\r\n",
      "        img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "        pipeline=None)\r\n",
      "]\r\n",
      "test_list = [\r\n",
      "    dict(\r\n",
      "        type='TextDetDataset',\r\n",
      "        img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "        ann_file='tests/data/toy_dataset/instances_test.txt',\r\n",
      "        loader=dict(\r\n",
      "            type='HardDiskLoader',\r\n",
      "            repeat=1,\r\n",
      "            parser=dict(\r\n",
      "                type='LineJsonParser',\r\n",
      "                keys=['file_name', 'height', 'width', 'annotations'])),\r\n",
      "        pipeline=None,\r\n",
      "        test_mode=True)\r\n",
      "]\r\n",
      "img_norm_cfg = dict(\r\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\r\n",
      "train_pipeline_r18 = [\r\n",
      "    dict(type='LoadImageFromFile', color_type='color_ignore_orientation'),\r\n",
      "    dict(\r\n",
      "        type='LoadTextAnnotations',\r\n",
      "        with_bbox=True,\r\n",
      "        with_mask=True,\r\n",
      "        poly2mask=False),\r\n",
      "    dict(type='ColorJitter', brightness=0.12549019607843137, saturation=0.5),\r\n",
      "    dict(\r\n",
      "        type='Normalize',\r\n",
      "        mean=[123.675, 116.28, 103.53],\r\n",
      "        std=[58.395, 57.12, 57.375],\r\n",
      "        to_rgb=True),\r\n",
      "    dict(\r\n",
      "        type='ImgAug',\r\n",
      "        args=[['Fliplr', 0.5], {\r\n",
      "            'cls': 'Affine',\r\n",
      "            'rotate': [-10, 10]\r\n",
      "        }, ['Resize', [0.5, 3.0]]]),\r\n",
      "    dict(type='EastRandomCrop', target_size=(640, 640)),\r\n",
      "    dict(type='DBNetTargets', shrink_ratio=0.4),\r\n",
      "    dict(type='Pad', size_divisor=32),\r\n",
      "    dict(\r\n",
      "        type='CustomFormatBundle',\r\n",
      "        keys=['gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'],\r\n",
      "        visualize=dict(flag=False, boundary_key='gt_shrink')),\r\n",
      "    dict(\r\n",
      "        type='Collect',\r\n",
      "        keys=['img', 'gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'])\r\n",
      "]\r\n",
      "test_pipeline_1333_736 = [\r\n",
      "    dict(type='LoadImageFromFile', color_type='color_ignore_orientation'),\r\n",
      "    dict(\r\n",
      "        type='MultiScaleFlipAug',\r\n",
      "        img_scale=(1333, 736),\r\n",
      "        flip=False,\r\n",
      "        transforms=[\r\n",
      "            dict(type='Resize', img_scale=(2944, 736), keep_ratio=True),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='ImageToTensor', keys=['img']),\r\n",
      "            dict(type='Collect', keys=['img'])\r\n",
      "        ])\r\n",
      "]\r\n",
      "img_norm_cfg_r50dcnv2 = dict(\r\n",
      "    mean=[122.67891434, 116.66876762, 104.00698793],\r\n",
      "    std=[58.395, 57.12, 57.375],\r\n",
      "    to_rgb=True)\r\n",
      "train_pipeline_r50dcnv2 = [\r\n",
      "    dict(type='LoadImageFromFile', color_type='color_ignore_orientation'),\r\n",
      "    dict(\r\n",
      "        type='LoadTextAnnotations',\r\n",
      "        with_bbox=True,\r\n",
      "        with_mask=True,\r\n",
      "        poly2mask=False),\r\n",
      "    dict(type='ColorJitter', brightness=0.12549019607843137, saturation=0.5),\r\n",
      "    dict(\r\n",
      "        type='Normalize',\r\n",
      "        mean=[122.67891434, 116.66876762, 104.00698793],\r\n",
      "        std=[58.395, 57.12, 57.375],\r\n",
      "        to_rgb=True),\r\n",
      "    dict(\r\n",
      "        type='ImgAug',\r\n",
      "        args=[['Fliplr', 0.5], {\r\n",
      "            'cls': 'Affine',\r\n",
      "            'rotate': [-10, 10]\r\n",
      "        }, ['Resize', [0.5, 3.0]]]),\r\n",
      "    dict(type='EastRandomCrop', target_size=(640, 640)),\r\n",
      "    dict(type='DBNetTargets', shrink_ratio=0.4),\r\n",
      "    dict(type='Pad', size_divisor=32),\r\n",
      "    dict(\r\n",
      "        type='CustomFormatBundle',\r\n",
      "        keys=['gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'],\r\n",
      "        visualize=dict(flag=False, boundary_key='gt_shrink')),\r\n",
      "    dict(\r\n",
      "        type='Collect',\r\n",
      "        keys=['img', 'gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'])\r\n",
      "]\r\n",
      "test_pipeline_4068_1024 = [\r\n",
      "    dict(type='LoadImageFromFile', color_type='color_ignore_orientation'),\r\n",
      "    dict(\r\n",
      "        type='MultiScaleFlipAug',\r\n",
      "        img_scale=(4068, 1024),\r\n",
      "        flip=False,\r\n",
      "        transforms=[\r\n",
      "            dict(type='Resize', img_scale=(2944, 736), keep_ratio=True),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[122.67891434, 116.66876762, 104.00698793],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='ImageToTensor', keys=['img']),\r\n",
      "            dict(type='Collect', keys=['img'])\r\n",
      "        ])\r\n",
      "]\r\n",
      "data = dict(\r\n",
      "    samples_per_gpu=8,\r\n",
      "    workers_per_gpu=4,\r\n",
      "    val_dataloader=dict(samples_per_gpu=1),\r\n",
      "    test_dataloader=dict(samples_per_gpu=1),\r\n",
      "    train=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='TextDetDataset',\r\n",
      "                img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "                ann_file='tests/data/toy_dataset/instances_test.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=4,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineJsonParser',\r\n",
      "                        keys=['file_name', 'height', 'width', 'annotations'])),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=False),\r\n",
      "            dict(\r\n",
      "                type='IcdarDataset',\r\n",
      "                ann_file='tests/data/toy_dataset/instances_test.json',\r\n",
      "                img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "                pipeline=None)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(\r\n",
      "                type='LoadImageFromFile',\r\n",
      "                color_type='color_ignore_orientation'),\r\n",
      "            dict(\r\n",
      "                type='LoadTextAnnotations',\r\n",
      "                with_bbox=True,\r\n",
      "                with_mask=True,\r\n",
      "                poly2mask=False),\r\n",
      "            dict(\r\n",
      "                type='ColorJitter',\r\n",
      "                brightness=0.12549019607843137,\r\n",
      "                saturation=0.5),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[122.67891434, 116.66876762, 104.00698793],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(\r\n",
      "                type='ImgAug',\r\n",
      "                args=[['Fliplr', 0.5], {\r\n",
      "                    'cls': 'Affine',\r\n",
      "                    'rotate': [-10, 10]\r\n",
      "                }, ['Resize', [0.5, 3.0]]]),\r\n",
      "            dict(type='EastRandomCrop', target_size=(640, 640)),\r\n",
      "            dict(type='DBNetTargets', shrink_ratio=0.4),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(\r\n",
      "                type='CustomFormatBundle',\r\n",
      "                keys=['gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'],\r\n",
      "                visualize=dict(flag=False, boundary_key='gt_shrink')),\r\n",
      "            dict(\r\n",
      "                type='Collect',\r\n",
      "                keys=[\r\n",
      "                    'img', 'gt_shrink', 'gt_shrink_mask', 'gt_thr',\r\n",
      "                    'gt_thr_mask'\r\n",
      "                ])\r\n",
      "        ]),\r\n",
      "    val=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='TextDetDataset',\r\n",
      "                img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "                ann_file='tests/data/toy_dataset/instances_test.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineJsonParser',\r\n",
      "                        keys=['file_name', 'height', 'width', 'annotations'])),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=True)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(\r\n",
      "                type='LoadImageFromFile',\r\n",
      "                color_type='color_ignore_orientation'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(4068, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(\r\n",
      "                        type='Resize', img_scale=(2944, 736), keep_ratio=True),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[122.67891434, 116.66876762, 104.00698793],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='ImageToTensor', keys=['img']),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ]),\r\n",
      "    test=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='TextDetDataset',\r\n",
      "                img_prefix='tests/data/toy_dataset/imgs',\r\n",
      "                ann_file='tests/data/toy_dataset/instances_test.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineJsonParser',\r\n",
      "                        keys=['file_name', 'height', 'width', 'annotations'])),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=True)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(\r\n",
      "                type='LoadImageFromFile',\r\n",
      "                color_type='color_ignore_orientation'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(4068, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(\r\n",
      "                        type='Resize', img_scale=(2944, 736), keep_ratio=True),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[122.67891434, 116.66876762, 104.00698793],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='ImageToTensor', keys=['img']),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ]))\r\n",
      "evaluation = dict(interval=100, metric='hmean-iou')\r\n",
      "work_dir = './work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom'\r\n",
      "gpu_ids = [0]\r\n",
      "\r\n",
      "2022-02-14 12:19:49,765 - mmocr - INFO - Set random seed to 736053026, deterministic: False\r\n",
      "2022-02-14 12:19:49,984 - mmocr - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\r\n",
      "2022-02-14 12:19:49,984 - mmcv - INFO - load model from: torchvision://resnet50\r\n",
      "2022-02-14 12:19:49,984 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\r\n",
      "2022-02-14 12:19:50,156 - mmcv - WARNING - The model and loaded state dict do not match exactly\r\n",
      "\r\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\r\n",
      "\r\n",
      "missing keys in source state_dict: layer2.0.conv2.conv_offset.weight, layer2.0.conv2.conv_offset.bias, layer2.1.conv2.conv_offset.weight, layer2.1.conv2.conv_offset.bias, layer2.2.conv2.conv_offset.weight, layer2.2.conv2.conv_offset.bias, layer2.3.conv2.conv_offset.weight, layer2.3.conv2.conv_offset.bias, layer3.0.conv2.conv_offset.weight, layer3.0.conv2.conv_offset.bias, layer3.1.conv2.conv_offset.weight, layer3.1.conv2.conv_offset.bias, layer3.2.conv2.conv_offset.weight, layer3.2.conv2.conv_offset.bias, layer3.3.conv2.conv_offset.weight, layer3.3.conv2.conv_offset.bias, layer3.4.conv2.conv_offset.weight, layer3.4.conv2.conv_offset.bias, layer3.5.conv2.conv_offset.weight, layer3.5.conv2.conv_offset.bias, layer4.0.conv2.conv_offset.weight, layer4.0.conv2.conv_offset.bias, layer4.1.conv2.conv_offset.weight, layer4.1.conv2.conv_offset.bias, layer4.2.conv2.conv_offset.weight, layer4.2.conv2.conv_offset.bias\r\n",
      "\r\n",
      "2022-02-14 12:19:50,184 - mmocr - INFO - initialize DBHead with init_cfg [{'type': 'Kaiming', 'layer': 'Conv'}, {'type': 'Constant', 'layer': 'BatchNorm', 'val': 1.0, 'bias': 0.0001}]\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/apis/train.py:86: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\r\n",
      "  'please set `runner` in your config.', UserWarning)\r\n",
      "2022-02-14 12:19:54,468 - mmocr - INFO - load checkpoint from local path: checkpoints/textdet/dbnet/res50dcnv2_synthtext.pth\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"tools/train.py\", line 224, in <module>\r\n",
      "    main()\r\n",
      "  File \"tools/train.py\", line 220, in main\r\n",
      "    meta=meta)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/apis/train.py\", line 154, in train_detector\r\n",
      "    runner.load_checkpoint(cfg.load_from)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/base_runner.py\", line 343, in load_checkpoint\r\n",
      "    revise_keys=revise_keys)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 528, in load_checkpoint\r\n",
      "    checkpoint = _load_checkpoint(filename, map_location, logger)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 467, in _load_checkpoint\r\n",
      "    return CheckpointLoader.load_checkpoint(filename, map_location, logger)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 245, in load_checkpoint\r\n",
      "    return checkpoint_loader(filename, map_location)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 261, in load_from_local\r\n",
      "    raise IOError(f'{filename} is not a checkpoint file')\r\n",
      "OSError: checkpoints/textdet/dbnet/res50dcnv2_synthtext.pth is not a checkpoint file\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/train.py {model_config_path_ref} --load-from {model_checkpoint_file}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing:\n",
    "./tools/dist_test.sh configs/textdet/dbnet/dbnet_r18_fpnc_1200e_icdar2015.py dbnet_r18_fpnc_sbn_1200e_icdar2015_20210329-ba3ab597.pth --eval hmean-iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /home/gsoykan20/.cache/torch/hub/checkpoints/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20211025-9fe3b590.pth\r\n",
      "2022-02-16 22:33:41,414 - root - INFO - ModulatedDeformConvPack backbone.layer2.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,415 - root - INFO - ModulatedDeformConvPack backbone.layer2.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,416 - root - INFO - ModulatedDeformConvPack backbone.layer2.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,416 - root - INFO - ModulatedDeformConvPack backbone.layer2.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,417 - root - INFO - ModulatedDeformConvPack backbone.layer3.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,418 - root - INFO - ModulatedDeformConvPack backbone.layer3.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,419 - root - INFO - ModulatedDeformConvPack backbone.layer3.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,420 - root - INFO - ModulatedDeformConvPack backbone.layer3.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,421 - root - INFO - ModulatedDeformConvPack backbone.layer3.4.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,422 - root - INFO - ModulatedDeformConvPack backbone.layer3.5.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,423 - root - INFO - ModulatedDeformConvPack backbone.layer4.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,427 - root - INFO - ModulatedDeformConvPack backbone.layer4.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:33:41,429 - root - INFO - ModulatedDeformConvPack backbone.layer4.2.conv2 is upgraded to version 2.\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>           ] 7/10, 3.4 task/s, elapsed: 2s, ETA:     1s/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/textdet/postprocess/utils.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n",
      "  expanded = np.array(offset.Execute(distance))\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 3.6 task/s, elapsed: 3s, ETA:     0s\r\n",
      "Evaluateing tests/data/comics_speech_bubble_dataset/test/instances_test.json with 10 images now\r\n",
      "\r\n",
      "Evaluating hmean-iou...\r\n",
      "thr 0.30, recall: 0.605, precision: 0.556, hmean: 0.580\r\n",
      "thr 0.40, recall: 0.605, precision: 0.627, hmean: 0.616\r\n",
      "thr 0.50, recall: 0.605, precision: 0.683, hmean: 0.642\r\n",
      "thr 0.60, recall: 0.605, precision: 0.697, hmean: 0.648\r\n",
      "thr 0.70, recall: 0.596, precision: 0.739, hmean: 0.660\r\n",
      "thr 0.80, recall: 0.544, precision: 0.747, hmean: 0.629\r\n",
      "thr 0.90, recall: 0.333, precision: 0.884, hmean: 0.484\r\n",
      "{'0_hmean-iou:recall': 0.5964912280701754, '0_hmean-iou:precision': 0.7391304347826086, '0_hmean-iou:hmean': 0.6601941747572816}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {model_checkpoint_file} --eval hmean-iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom/best_0_hmean-iou:hmean_epoch_9.pth\r\n",
      "2022-02-16 22:38:15,570 - root - INFO - ModulatedDeformConvPack backbone.layer2.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,571 - root - INFO - ModulatedDeformConvPack backbone.layer2.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,572 - root - INFO - ModulatedDeformConvPack backbone.layer2.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,573 - root - INFO - ModulatedDeformConvPack backbone.layer2.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,573 - root - INFO - ModulatedDeformConvPack backbone.layer3.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,575 - root - INFO - ModulatedDeformConvPack backbone.layer3.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,576 - root - INFO - ModulatedDeformConvPack backbone.layer3.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,577 - root - INFO - ModulatedDeformConvPack backbone.layer3.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,578 - root - INFO - ModulatedDeformConvPack backbone.layer3.4.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,579 - root - INFO - ModulatedDeformConvPack backbone.layer3.5.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,580 - root - INFO - ModulatedDeformConvPack backbone.layer4.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,584 - root - INFO - ModulatedDeformConvPack backbone.layer4.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-16 22:38:15,586 - root - INFO - ModulatedDeformConvPack backbone.layer4.2.conv2 is upgraded to version 2.\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 3.3 task/s, elapsed: 3s, ETA:     0s\r\n",
      "Evaluateing tests/data/comics_speech_bubble_dataset/test/instances_test.json with 10 images now\r\n",
      "\r\n",
      "Evaluating hmean-iou...\r\n",
      "thr 0.30, recall: 0.877, precision: 0.658, hmean: 0.752\r\n",
      "thr 0.40, recall: 0.877, precision: 0.752, hmean: 0.810\r\n",
      "thr 0.50, recall: 0.877, precision: 0.806, hmean: 0.840\r\n",
      "thr 0.60, recall: 0.868, precision: 0.818, hmean: 0.843\r\n",
      "thr 0.70, recall: 0.860, precision: 0.891, hmean: 0.875\r\n",
      "thr 0.80, recall: 0.763, precision: 0.935, hmean: 0.841\r\n",
      "thr 0.90, recall: 0.035, precision: 1.000, hmean: 0.068\r\n",
      "{'0_hmean-iou:recall': 0.8596491228070176, '0_hmean-iou:precision': 0.8909090909090909, '0_hmean-iou:hmean': 0.875}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {finetuned_model_checkpoint_file} --eval hmean-iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom/best_0_hmean-iou:hmean_epoch_4.pth\r\n",
      "2022-02-17 03:15:11,930 - root - INFO - ModulatedDeformConvPack backbone.layer2.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,931 - root - INFO - ModulatedDeformConvPack backbone.layer2.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,932 - root - INFO - ModulatedDeformConvPack backbone.layer2.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,932 - root - INFO - ModulatedDeformConvPack backbone.layer2.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,933 - root - INFO - ModulatedDeformConvPack backbone.layer3.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,934 - root - INFO - ModulatedDeformConvPack backbone.layer3.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,936 - root - INFO - ModulatedDeformConvPack backbone.layer3.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,937 - root - INFO - ModulatedDeformConvPack backbone.layer3.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,938 - root - INFO - ModulatedDeformConvPack backbone.layer3.4.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,939 - root - INFO - ModulatedDeformConvPack backbone.layer3.5.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,940 - root - INFO - ModulatedDeformConvPack backbone.layer4.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,944 - root - INFO - ModulatedDeformConvPack backbone.layer4.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:15:11,946 - root - INFO - ModulatedDeformConvPack backbone.layer4.2.conv2 is upgraded to version 2.\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 4.5 task/s, elapsed: 2s, ETA:     0s\r\n",
      "Evaluateing tests/data/comics_speech_bubble_dataset/test/instances_test.json with 11 images now\r\n",
      "\r\n",
      "Evaluating hmean-iou...\r\n",
      "thr 0.30, recall: 0.869, precision: 0.785, hmean: 0.825\r\n",
      "thr 0.40, recall: 0.869, precision: 0.837, hmean: 0.853\r\n",
      "thr 0.50, recall: 0.863, precision: 0.873, hmean: 0.868\r\n",
      "thr 0.60, recall: 0.806, precision: 0.884, hmean: 0.843\r\n",
      "thr 0.70, recall: 0.650, precision: 0.897, hmean: 0.754\r\n",
      "thr 0.80, recall: 0.225, precision: 0.947, hmean: 0.364\r\n",
      "thr 0.90, recall: 0.000, precision: 0.000, hmean: 0.000\r\n",
      "{'0_hmean-iou:recall': 0.8625, '0_hmean-iou:precision': 0.8734177215189873, '0_hmean-iou:hmean': 0.8679245283018868}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {finetuned_model_80_checkpoint_file} --eval hmean-iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom_90train_10test/best_0_hmean-iou:hmean_epoch_5.pth\r\n",
      "2022-02-17 03:42:07,778 - root - INFO - ModulatedDeformConvPack backbone.layer2.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,779 - root - INFO - ModulatedDeformConvPack backbone.layer2.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,780 - root - INFO - ModulatedDeformConvPack backbone.layer2.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,780 - root - INFO - ModulatedDeformConvPack backbone.layer2.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,781 - root - INFO - ModulatedDeformConvPack backbone.layer3.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,783 - root - INFO - ModulatedDeformConvPack backbone.layer3.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,784 - root - INFO - ModulatedDeformConvPack backbone.layer3.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,785 - root - INFO - ModulatedDeformConvPack backbone.layer3.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,786 - root - INFO - ModulatedDeformConvPack backbone.layer3.4.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,787 - root - INFO - ModulatedDeformConvPack backbone.layer3.5.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,788 - root - INFO - ModulatedDeformConvPack backbone.layer4.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,791 - root - INFO - ModulatedDeformConvPack backbone.layer4.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-17 03:42:07,794 - root - INFO - ModulatedDeformConvPack backbone.layer4.2.conv2 is upgraded to version 2.\r\n",
      "[                                                  ] 0/10, elapsed: 0s, ETA:/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/textdet/postprocess/utils.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n",
      "  expanded = np.array(offset.Execute(distance))\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 4.1 task/s, elapsed: 2s, ETA:     0s\r\n",
      "Evaluateing tests/data/comics_speech_bubble_dataset/test/instances_test.json with 10 images now\r\n",
      "\r\n",
      "Evaluating hmean-iou...\r\n",
      "thr 0.30, recall: 0.915, precision: 0.590, hmean: 0.717\r\n",
      "thr 0.40, recall: 0.915, precision: 0.825, hmean: 0.868\r\n",
      "thr 0.50, recall: 0.915, precision: 0.861, hmean: 0.887\r\n",
      "thr 0.60, recall: 0.915, precision: 0.894, hmean: 0.904\r\n",
      "thr 0.70, recall: 0.884, precision: 0.919, hmean: 0.901\r\n",
      "thr 0.80, recall: 0.519, precision: 0.985, hmean: 0.680\r\n",
      "thr 0.90, recall: 0.000, precision: 0.000, hmean: 0.000\r\n",
      "{'0_hmean-iou:recall': 0.9147286821705426, '0_hmean-iou:precision': 0.8939393939393939, '0_hmean-iou:hmean': 0.9042145593869731}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {finetuned_model_100_checkpoint_file} --eval hmean-iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "load checkpoint from local path: /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/dbnet_r50dcnv2_fpnc_1200e_icdar2015_custom_140_20_adam6/best_0_hmean-iou:hmean_epoch_3.pth\r\n",
      "2022-02-21 17:02:29,734 - root - INFO - ModulatedDeformConvPack backbone.layer2.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,735 - root - INFO - ModulatedDeformConvPack backbone.layer2.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,736 - root - INFO - ModulatedDeformConvPack backbone.layer2.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,737 - root - INFO - ModulatedDeformConvPack backbone.layer2.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,737 - root - INFO - ModulatedDeformConvPack backbone.layer3.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,739 - root - INFO - ModulatedDeformConvPack backbone.layer3.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,741 - root - INFO - ModulatedDeformConvPack backbone.layer3.2.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,742 - root - INFO - ModulatedDeformConvPack backbone.layer3.3.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,743 - root - INFO - ModulatedDeformConvPack backbone.layer3.4.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,744 - root - INFO - ModulatedDeformConvPack backbone.layer3.5.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,746 - root - INFO - ModulatedDeformConvPack backbone.layer4.0.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,750 - root - INFO - ModulatedDeformConvPack backbone.layer4.1.conv2 is upgraded to version 2.\r\n",
      "2022-02-21 17:02:29,752 - root - INFO - ModulatedDeformConvPack backbone.layer4.2.conv2 is upgraded to version 2.\r\n",
      "[>>>>>>>>>>                        ] 6/20, 3.1 task/s, elapsed: 2s, ETA:     4s/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/textdet/postprocess/utils.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n",
      "  expanded = np.array(offset.Execute(distance))\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 20/20, 3.7 task/s, elapsed: 5s, ETA:     0s\r\n",
      "Evaluateing tests/data/comics_speech_bubble_dataset/test/instances_test.json with 20 images now\r\n",
      "\r\n",
      "Evaluating hmean-iou...\r\n",
      "thr 0.30, recall: 0.952, precision: 0.902, hmean: 0.927\r\n",
      "thr 0.40, recall: 0.952, precision: 0.970, hmean: 0.961\r\n",
      "thr 0.50, recall: 0.949, precision: 0.974, hmean: 0.961\r\n",
      "thr 0.60, recall: 0.945, precision: 0.981, hmean: 0.963\r\n",
      "thr 0.70, recall: 0.908, precision: 0.988, hmean: 0.946\r\n",
      "thr 0.80, recall: 0.662, precision: 0.994, hmean: 0.795\r\n",
      "thr 0.90, recall: 0.029, precision: 1.000, hmean: 0.057\r\n",
      "{'0_hmean-iou:recall': 0.9448529411764706, '0_hmean-iou:precision': 0.9809160305343512, '0_hmean-iou:hmean': 0.9625468164794007}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {finetuned_model_160_checkpoint_file} --eval hmean-iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-66d3b219",
   "language": "python",
   "display_name": "open mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}