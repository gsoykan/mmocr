{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "dataset iÃ§in: configs/_base_/recog_datasets/toy_data.py\n",
    "\n",
    "anno file format:\n",
    "```\n",
    "1223731.jpg GRAND\n",
    "1223733.jpg HOTEL\n",
    "1223732.jpg HOTEL\n",
    "1223729.jpg PACIFIC\n",
    "1036169.jpg 03/09/2009\n",
    "1190237.jpg ANING\n",
    "1058891.jpg Virgin\n",
    "1058892.jpg america\n",
    "1240078.jpg ATTACK\n",
    "1210236.jpg DAVIDSON\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "root = 'tests/data/ocr_toy_dataset'\n",
    "img_prefix = f'{root}/imgs'\n",
    "train_anno_file1 = f'{root}/label.txt'\n",
    "\n",
    "train1 = dict(\n",
    "    type=dataset_type,\n",
    "    img_prefix=img_prefix,\n",
    "    ann_file=train_anno_file1,\n",
    "    loader=dict(\n",
    "        type='HardDiskLoader',\n",
    "        repeat=100,\n",
    "        parser=dict(\n",
    "            type='LineStrParser',\n",
    "            keys=['filename', 'text'],\n",
    "            keys_idx=[0, 1],\n",
    "            separator=' ')),\n",
    "    pipeline=None,\n",
    "    test_mode=False)\n",
    "```\n",
    "\n",
    "eval metrics\n",
    "\n",
    "```\n",
    "\n",
    "         eval_res (dict[str: float]): Metric dict for text recognition, include:\n",
    "             - word_acc: Accuracy in word level.\n",
    "             - word_acc_ignore_case: Accuracy in word level, ignore letter case.\n",
    "             - word_acc_ignore_case_symbol: Accuracy in word level, ignore\n",
    "                 letter case and symbol. (default metric for\n",
    "                 academic evaluation)\n",
    "             - char_recall: Recall in character level, ignore\n",
    "                 letter case and symbol.\n",
    "             - char_precision: Precision in character level, ignore\n",
    "                 letter case and symbol.\n",
    "             - 1-N.E.D: 1 - normalized_edit_distance. \n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#TODO: evaluate as it is right now with all metric\n",
    "#      0_word_acc: 0.0448, 0_word_acc_ignore_case: 0.0448, 0_word_acc_ignore_case_symbol: 0.0448, 0_char_recall: 0.1769, 0_char_precision: 0.2884, 0_1-N.E.D: 0.1454\n",
    "\n",
    "model_config_path_ref = \"/home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/nrtr/nrtr_r31_1by8_1by4_custom.py\"\n",
    "\n",
    "model_checkpoint_file = \"/home/gsoykan20/.cache/torch/hub/checkpoints/nrtr_r31_1by8_1by4_academic_20211123-e1fdb322.pth\"\n",
    "\n",
    "finetuned_model_51img_20ep = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom_20epoch_51img/best_0_1-N.E.D_epoch_10.pth\"\n",
    "\n",
    "finetuned_model_89img_6ep = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom/best_0_char_precision_epoch_3.pth\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "2022-02-21 10:42:43,597 - mmocr - INFO - Environment info:\r\n",
      "------------------------------------------------------------\r\n",
      "sys.platform: linux\r\n",
      "Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]\r\n",
      "CUDA available: True\r\n",
      "GPU 0: Quadro RTX 3000\r\n",
      "CUDA_HOME: /usr/local/cuda\r\n",
      "NVCC: Build cuda_11.4.r11.4/compiler.30300941_0\r\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\n",
      "PyTorch: 1.6.0\r\n",
      "PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 7.3\r\n",
      "  - C++ Version: 201402\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 10.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n",
      "  - CuDNN 7.6.3\r\n",
      "  - Magma 2.5.2\r\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \r\n",
      "\r\n",
      "TorchVision: 0.7.0\r\n",
      "OpenCV: 4.5.4\r\n",
      "MMCV: 1.3.17\r\n",
      "MMCV Compiler: GCC 7.3\r\n",
      "MMCV CUDA Compiler: 10.1\r\n",
      "MMOCR: 0.4.1+1aae45b\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "2022-02-21 10:42:44,325 - mmocr - INFO - Distributed training: False\r\n",
      "2022-02-21 10:42:45,081 - mmocr - INFO - Config:\r\n",
      "checkpoint_config = dict(interval=1)\r\n",
      "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\r\n",
      "dist_params = dict(backend='nccl')\r\n",
      "log_level = 'INFO'\r\n",
      "load_from = None\r\n",
      "resume_from = None\r\n",
      "workflow = [('train', 1)]\r\n",
      "opencv_num_threads = 0\r\n",
      "mp_start_method = 'fork'\r\n",
      "optimizer = dict(type='SGD', lr=0.08, momentum=0.9, weight_decay=0.0001)\r\n",
      "optimizer_config = dict(grad_clip=None)\r\n",
      "lr_config = dict(\r\n",
      "    policy='step',\r\n",
      "    warmup='linear',\r\n",
      "    warmup_iters=500,\r\n",
      "    warmup_ratio=0.001,\r\n",
      "    step=[80, 128])\r\n",
      "total_epochs = 160\r\n",
      "img_norm_cfg = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='ResizeOCR',\r\n",
      "        height=32,\r\n",
      "        min_width=32,\r\n",
      "        max_width=160,\r\n",
      "        keep_aspect_ratio=True,\r\n",
      "        width_downsample_ratio=0.25),\r\n",
      "    dict(type='ToTensorOCR'),\r\n",
      "    dict(\r\n",
      "        type='NormalizeOCR',\r\n",
      "        mean=[0.485, 0.456, 0.406],\r\n",
      "        std=[0.229, 0.224, 0.225]),\r\n",
      "    dict(\r\n",
      "        type='Collect',\r\n",
      "        keys=['img'],\r\n",
      "        meta_keys=[\r\n",
      "            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'\r\n",
      "        ])\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='ResizeOCR',\r\n",
      "        height=32,\r\n",
      "        min_width=32,\r\n",
      "        max_width=160,\r\n",
      "        keep_aspect_ratio=True),\r\n",
      "    dict(type='ToTensorOCR'),\r\n",
      "    dict(\r\n",
      "        type='NormalizeOCR',\r\n",
      "        mean=[0.485, 0.456, 0.406],\r\n",
      "        std=[0.229, 0.224, 0.225]),\r\n",
      "    dict(\r\n",
      "        type='Collect',\r\n",
      "        keys=['img'],\r\n",
      "        meta_keys=[\r\n",
      "            'filename', 'ori_shape', 'resize_shape', 'valid_ratio',\r\n",
      "            'img_norm_cfg', 'ori_filename', 'img_shape'\r\n",
      "        ])\r\n",
      "]\r\n",
      "dataset_type = 'OCRDataset'\r\n",
      "root = 'tests/data/ocr_comics_speech_bubble_dataset'\r\n",
      "train_img_prefix = 'tests/data/ocr_comics_speech_bubble_dataset/train/imgs'\r\n",
      "train_anno_file1 = 'tests/data/ocr_comics_speech_bubble_dataset/train/label.txt'\r\n",
      "test_img_prefix = 'tests/data/ocr_comics_speech_bubble_dataset/test/imgs'\r\n",
      "test_anno_file1 = 'tests/data/ocr_comics_speech_bubble_dataset/test/label.txt'\r\n",
      "train = dict(\r\n",
      "    type='OCRDataset',\r\n",
      "    img_prefix='tests/data/ocr_comics_speech_bubble_dataset/train/imgs',\r\n",
      "    ann_file='tests/data/ocr_comics_speech_bubble_dataset/train/label.txt',\r\n",
      "    loader=dict(\r\n",
      "        type='HardDiskLoader',\r\n",
      "        repeat=1,\r\n",
      "        parser=dict(\r\n",
      "            type='LineStrParser',\r\n",
      "            keys=['filename', 'text'],\r\n",
      "            keys_idx=[0, 1],\r\n",
      "            separator=' ')),\r\n",
      "    pipeline=None,\r\n",
      "    test_mode=False)\r\n",
      "test = dict(\r\n",
      "    type='OCRDataset',\r\n",
      "    img_prefix='tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "    ann_file='tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "    loader=dict(\r\n",
      "        type='HardDiskLoader',\r\n",
      "        repeat=1,\r\n",
      "        parser=dict(\r\n",
      "            type='LineStrParser',\r\n",
      "            keys=['filename', 'text'],\r\n",
      "            keys_idx=[0, 1],\r\n",
      "            separator=' ')),\r\n",
      "    pipeline=None,\r\n",
      "    test_mode=True)\r\n",
      "train_list = [\r\n",
      "    dict(\r\n",
      "        type='OCRDataset',\r\n",
      "        img_prefix='tests/data/ocr_comics_speech_bubble_dataset/train/imgs',\r\n",
      "        ann_file='tests/data/ocr_comics_speech_bubble_dataset/train/label.txt',\r\n",
      "        loader=dict(\r\n",
      "            type='HardDiskLoader',\r\n",
      "            repeat=1,\r\n",
      "            parser=dict(\r\n",
      "                type='LineStrParser',\r\n",
      "                keys=['filename', 'text'],\r\n",
      "                keys_idx=[0, 1],\r\n",
      "                separator=' ')),\r\n",
      "        pipeline=None,\r\n",
      "        test_mode=False)\r\n",
      "]\r\n",
      "test_list = [\r\n",
      "    dict(\r\n",
      "        type='OCRDataset',\r\n",
      "        img_prefix='tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "        ann_file='tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "        loader=dict(\r\n",
      "            type='HardDiskLoader',\r\n",
      "            repeat=1,\r\n",
      "            parser=dict(\r\n",
      "                type='LineStrParser',\r\n",
      "                keys=['filename', 'text'],\r\n",
      "                keys_idx=[0, 1],\r\n",
      "                separator=' ')),\r\n",
      "        pipeline=None,\r\n",
      "        test_mode=True)\r\n",
      "]\r\n",
      "label_convertor = dict(\r\n",
      "    type='AttnConvertor', dict_type='DICT90', with_unknown=True)\r\n",
      "model = dict(\r\n",
      "    type='NRTR',\r\n",
      "    backbone=dict(\r\n",
      "        type='ResNet31OCR',\r\n",
      "        layers=[1, 2, 5, 3],\r\n",
      "        channels=[32, 64, 128, 256, 512, 512],\r\n",
      "        stage4_pool_cfg=dict(kernel_size=(2, 1), stride=(2, 1)),\r\n",
      "        last_stage_pool=False),\r\n",
      "    encoder=dict(type='NRTREncoder'),\r\n",
      "    decoder=dict(type='NRTRDecoder'),\r\n",
      "    loss=dict(type='TFLoss'),\r\n",
      "    label_convertor=dict(\r\n",
      "        type='AttnConvertor', dict_type='DICT90', with_unknown=True),\r\n",
      "    max_seq_len=40)\r\n",
      "data = dict(\r\n",
      "    samples_per_gpu=8,\r\n",
      "    workers_per_gpu=4,\r\n",
      "    train=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='OCRDataset',\r\n",
      "                img_prefix=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/train/imgs',\r\n",
      "                ann_file=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/train/label.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineStrParser',\r\n",
      "                        keys=['filename', 'text'],\r\n",
      "                        keys_idx=[0, 1],\r\n",
      "                        separator=' ')),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=False)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='ResizeOCR',\r\n",
      "                height=32,\r\n",
      "                min_width=32,\r\n",
      "                max_width=160,\r\n",
      "                keep_aspect_ratio=True,\r\n",
      "                width_downsample_ratio=0.25),\r\n",
      "            dict(type='ToTensorOCR'),\r\n",
      "            dict(\r\n",
      "                type='NormalizeOCR',\r\n",
      "                mean=[0.485, 0.456, 0.406],\r\n",
      "                std=[0.229, 0.224, 0.225]),\r\n",
      "            dict(\r\n",
      "                type='Collect',\r\n",
      "                keys=['img'],\r\n",
      "                meta_keys=[\r\n",
      "                    'filename', 'ori_shape', 'resize_shape', 'text',\r\n",
      "                    'valid_ratio'\r\n",
      "                ])\r\n",
      "        ]),\r\n",
      "    val=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='OCRDataset',\r\n",
      "                img_prefix=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "                ann_file=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineStrParser',\r\n",
      "                        keys=['filename', 'text'],\r\n",
      "                        keys_idx=[0, 1],\r\n",
      "                        separator=' ')),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=True)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='ResizeOCR',\r\n",
      "                height=32,\r\n",
      "                min_width=32,\r\n",
      "                max_width=160,\r\n",
      "                keep_aspect_ratio=True),\r\n",
      "            dict(type='ToTensorOCR'),\r\n",
      "            dict(\r\n",
      "                type='NormalizeOCR',\r\n",
      "                mean=[0.485, 0.456, 0.406],\r\n",
      "                std=[0.229, 0.224, 0.225]),\r\n",
      "            dict(\r\n",
      "                type='Collect',\r\n",
      "                keys=['img'],\r\n",
      "                meta_keys=[\r\n",
      "                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio',\r\n",
      "                    'img_norm_cfg', 'ori_filename', 'img_shape'\r\n",
      "                ])\r\n",
      "        ]),\r\n",
      "    test=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='OCRDataset',\r\n",
      "                img_prefix=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "                ann_file=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineStrParser',\r\n",
      "                        keys=['filename', 'text'],\r\n",
      "                        keys_idx=[0, 1],\r\n",
      "                        separator=' ')),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=True)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='ResizeOCR',\r\n",
      "                height=32,\r\n",
      "                min_width=32,\r\n",
      "                max_width=160,\r\n",
      "                keep_aspect_ratio=True),\r\n",
      "            dict(type='ToTensorOCR'),\r\n",
      "            dict(\r\n",
      "                type='NormalizeOCR',\r\n",
      "                mean=[0.485, 0.456, 0.406],\r\n",
      "                std=[0.229, 0.224, 0.225]),\r\n",
      "            dict(\r\n",
      "                type='Collect',\r\n",
      "                keys=['img'],\r\n",
      "                meta_keys=[\r\n",
      "                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio',\r\n",
      "                    'img_norm_cfg', 'ori_filename', 'img_shape'\r\n",
      "                ])\r\n",
      "        ]))\r\n",
      "evaluation = dict(interval=1, metric='acc')\r\n",
      "work_dir = './work_dirs/nrtr_r31_1by8_1by4_custom'\r\n",
      "gpu_ids = [0]\r\n",
      "\r\n",
      "2022-02-21 10:42:45,081 - mmocr - INFO - Set random seed to 982286355, deterministic: False\r\n",
      "2022-02-21 10:42:45,427 - mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/apis/train.py:86: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\r\n",
      "  'please set `runner` in your config.', UserWarning)\r\n",
      "2022-02-21 10:42:47,251 - mmocr - INFO - Start running, host: gsoykan20@WS001, work_dir: /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom\r\n",
      "2022-02-21 10:42:47,251 - mmocr - INFO - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(NORMAL      ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(NORMAL      ) EvalHook                           \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(NORMAL      ) EvalHook                           \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(ABOVE_NORMAL) OptimizerHook                      \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(NORMAL      ) EvalHook                           \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(NORMAL      ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "2022-02-21 10:42:47,251 - mmocr - INFO - workflow: [('train', 1)], max: 160 epochs\r\n",
      "2022-02-21 10:42:47,251 - mmocr - INFO - Checkpoints will be saved to /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom by HardDiskBackend.\r\n",
      "[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\r\n",
      "2022-02-21 10:42:50,254 - mmocr - INFO - Epoch [1][5/73]\tlr: 7.194e-04, eta: 1:56:26, time: 0.598, data_time: 0.417, memory: 1384, loss_ce: 0.7225, loss: 0.7225\r\n",
      "2022-02-21 10:42:50,984 - mmocr - INFO - Epoch [1][10/73]\tlr: 1.519e-03, eta: 1:12:23, time: 0.146, data_time: 0.003, memory: 1384, loss_ce: 0.6072, loss: 0.6072\r\n",
      "2022-02-21 10:42:51,715 - mmocr - INFO - Epoch [1][15/73]\tlr: 2.318e-03, eta: 0:57:42, time: 0.146, data_time: 0.003, memory: 1384, loss_ce: 0.5804, loss: 0.5804\r\n",
      "2022-02-21 10:42:52,448 - mmocr - INFO - Epoch [1][20/73]\tlr: 3.117e-03, eta: 0:50:22, time: 0.146, data_time: 0.003, memory: 1384, loss_ce: 0.6480, loss: 0.6480\r\n",
      "2022-02-21 10:42:53,196 - mmocr - INFO - Epoch [1][25/73]\tlr: 3.916e-03, eta: 0:46:05, time: 0.150, data_time: 0.003, memory: 1384, loss_ce: 0.4829, loss: 0.4829\r\n",
      "2022-02-21 10:42:53,944 - mmocr - INFO - Epoch [1][30/73]\tlr: 4.715e-03, eta: 0:43:14, time: 0.150, data_time: 0.003, memory: 1384, loss_ce: 0.4994, loss: 0.4994\r\n",
      "2022-02-21 10:42:54,686 - mmocr - INFO - Epoch [1][35/73]\tlr: 5.515e-03, eta: 0:41:09, time: 0.149, data_time: 0.003, memory: 1384, loss_ce: 0.4595, loss: 0.4595\r\n",
      "2022-02-21 10:42:55,578 - mmocr - INFO - Epoch [1][40/73]\tlr: 6.314e-03, eta: 0:40:19, time: 0.178, data_time: 0.003, memory: 1384, loss_ce: 0.4327, loss: 0.4327\r\n",
      "2022-02-21 10:42:56,428 - mmocr - INFO - Epoch [1][45/73]\tlr: 7.113e-03, eta: 0:39:29, time: 0.170, data_time: 0.003, memory: 1384, loss_ce: 0.4176, loss: 0.4176\r\n",
      "2022-02-21 10:42:57,274 - mmocr - INFO - Epoch [1][50/73]\tlr: 7.912e-03, eta: 0:38:48, time: 0.169, data_time: 0.003, memory: 1384, loss_ce: 0.3992, loss: 0.3992\r\n",
      "2022-02-21 10:42:58,118 - mmocr - INFO - Epoch [1][55/73]\tlr: 8.711e-03, eta: 0:38:14, time: 0.169, data_time: 0.003, memory: 1384, loss_ce: 0.3629, loss: 0.3629\r\n",
      "2022-02-21 10:42:58,868 - mmocr - INFO - Epoch [1][60/73]\tlr: 9.511e-03, eta: 0:37:27, time: 0.150, data_time: 0.003, memory: 1384, loss_ce: 0.3446, loss: 0.3446\r\n",
      "2022-02-21 10:42:59,620 - mmocr - INFO - Epoch [1][65/73]\tlr: 1.031e-02, eta: 0:36:48, time: 0.150, data_time: 0.003, memory: 1384, loss_ce: 0.4202, loss: 0.4202\r\n",
      "2022-02-21 10:43:00,412 - mmocr - INFO - Epoch [1][70/73]\tlr: 1.111e-02, eta: 0:36:20, time: 0.158, data_time: 0.003, memory: 1384, loss_ce: 0.4238, loss: 0.4238\r\n",
      "2022-02-21 10:43:00,954 - mmocr - INFO - Saving checkpoint at 1 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 134/134, 21.5 task/s, elapsed: 6s, ETA:     0s2022-02-21 10:43:08,186 - mmocr - INFO - \r\n",
      "Evaluateing tests/data/ocr_comics_speech_bubble_dataset/test/label.txt with 134 images now\r\n",
      "2022-02-21 10:43:08,189 - mmocr - INFO - Exp name: nrtr_r31_1by8_1by4_custom.py\r\n",
      "2022-02-21 10:43:08,189 - mmocr - INFO - Epoch(val) [1][17]\t0_word_acc: 0.0224, 0_word_acc_ignore_case: 0.0224, 0_word_acc_ignore_case_symbol: 0.0224, 0_char_recall: 0.1577, 0_char_precision: 0.2284, 0_1-N.E.D: 0.1391\r\n",
      "2022-02-21 10:43:11,079 - mmocr - INFO - Epoch [2][5/73]\tlr: 1.239e-02, eta: 0:39:43, time: 0.576, data_time: 0.414, memory: 1384, loss_ce: 0.4191, loss: 0.4191\r\n",
      "2022-02-21 10:43:11,816 - mmocr - INFO - Epoch [2][10/73]\tlr: 1.319e-02, eta: 0:39:02, time: 0.147, data_time: 0.003, memory: 1384, loss_ce: 0.3994, loss: 0.3994\r\n",
      "2022-02-21 10:43:12,549 - mmocr - INFO - Epoch [2][15/73]\tlr: 1.399e-02, eta: 0:38:24, time: 0.147, data_time: 0.003, memory: 1384, loss_ce: 0.3756, loss: 0.3756\r\n",
      "2022-02-21 10:43:13,293 - mmocr - INFO - Epoch [2][20/73]\tlr: 1.479e-02, eta: 0:37:52, time: 0.149, data_time: 0.003, memory: 1384, loss_ce: 0.3676, loss: 0.3676\r\n",
      "2022-02-21 10:43:14,047 - mmocr - INFO - Epoch [2][25/73]\tlr: 1.558e-02, eta: 0:37:24, time: 0.151, data_time: 0.003, memory: 1384, loss_ce: 0.3213, loss: 0.3213\r\n",
      "2022-02-21 10:43:14,783 - mmocr - INFO - Epoch [2][30/73]\tlr: 1.638e-02, eta: 0:36:57, time: 0.147, data_time: 0.003, memory: 1384, loss_ce: 0.4020, loss: 0.4020\r\n",
      "2022-02-21 10:43:15,603 - mmocr - INFO - Epoch [2][35/73]\tlr: 1.718e-02, eta: 0:36:41, time: 0.164, data_time: 0.003, memory: 1384, loss_ce: 0.3617, loss: 0.3617\r\n",
      "2022-02-21 10:43:16,390 - mmocr - INFO - Epoch [2][40/73]\tlr: 1.798e-02, eta: 0:36:24, time: 0.158, data_time: 0.003, memory: 1384, loss_ce: 0.2797, loss: 0.2797\r\n",
      "2022-02-21 10:43:17,139 - mmocr - INFO - Epoch [2][45/73]\tlr: 1.878e-02, eta: 0:36:03, time: 0.150, data_time: 0.003, memory: 1384, loss_ce: 0.3758, loss: 0.3758\r\n",
      "2022-02-21 10:43:17,965 - mmocr - INFO - Epoch [2][50/73]\tlr: 1.958e-02, eta: 0:35:52, time: 0.165, data_time: 0.003, memory: 1384, loss_ce: 0.3521, loss: 0.3521\r\n",
      "2022-02-21 10:43:18,816 - mmocr - INFO - Epoch [2][55/73]\tlr: 2.038e-02, eta: 0:35:44, time: 0.171, data_time: 0.004, memory: 1384, loss_ce: 0.4386, loss: 0.4386\r\n",
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"tools/train.py\", line 224, in <module>\r\n",
      "    main()\r\n",
      "  File \"tools/train.py\", line 220, in main\r\n",
      "    meta=meta)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/apis/train.py\", line 155, in train_detector\r\n",
      "    runner.run(data_loaders, cfg.workflow)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 127, in run\r\n",
      "    epoch_runner(data_loaders[i], **kwargs)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 50, in train\r\n",
      "    self.run_iter(data_batch, train_mode=True, **kwargs)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 30, in run_iter\r\n",
      "    **kwargs)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/parallel/data_parallel.py\", line 67, in train_step\r\n",
      "    return self.module.train_step(*inputs[0], **kwargs[0])\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/textrecog/recognizer/base.py\", line 158, in train_step\r\n",
      "    losses = self(**data)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n",
      "    result = self.forward(*input, **kwargs)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py\", line 98, in new_func\r\n",
      "    return old_func(*args, **kwargs)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/textrecog/recognizer/base.py\", line 84, in forward\r\n",
      "    return self.forward_train(img, img_metas, **kwargs)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/textrecog/recognizer/encode_decode_recognizer.py\", line 107, in forward_train\r\n",
      "    out_enc = self.encoder(feat, img_metas)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n",
      "    result = self.forward(*input, **kwargs)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/textrecog/encoders/nrtr_encoder.py\", line 84, in forward\r\n",
      "    output = enc_layer(output, mask)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n",
      "    result = self.forward(*input, **kwargs)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/common/layers/transformer_layers.py\", line 71, in forward\r\n",
      "    x = residual + self.mlp(x)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n",
      "    result = self.forward(*input, **kwargs)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/models/common/modules/transformer_module.py\", line 123, in forward\r\n",
      "    x = self.w_2(x)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n",
      "    result = self.forward(*input, **kwargs)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/linear.py\", line 91, in forward\r\n",
      "    return F.linear(input, self.weight, self.bias)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/functional.py\", line 1678, in linear\r\n",
      "    output += bias\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "# --load-from\n",
    "!python tools/train.py {model_config_path_ref} --load-from {model_config_path_ref}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing\n",
    "\n",
    "python tools/test.py {model_config_path_ref} {model_checkpoint_file} --eval acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "load checkpoint from local path: /home/gsoykan20/.cache/torch/hub/checkpoints/nrtr_r31_1by8_1by4_academic_20211123-e1fdb322.pth\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 163/163, 27.0 task/s, elapsed: 6s, ETA:     0s\r\n",
      "Evaluateing tests/data/ocr_comics_speech_bubble_dataset/test/label.txt with 163 images now\r\n",
      "{'0_word_acc': 0.2454, '0_word_acc_ignore_case': 0.8957, '0_word_acc_ignore_case_symbol': 0.9509, '0_char_recall': 0.9942, '0_char_precision': 0.9827, '0_1-N.E.D': 0.9716}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {model_checkpoint_file} --eval acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "load checkpoint from local path: /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom/best_0_char_precision_epoch_3.pth\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 163/163, 26.2 task/s, elapsed: 6s, ETA:     0s\r\n",
      "Evaluateing tests/data/ocr_comics_speech_bubble_dataset/test/label.txt with 163 images now\r\n",
      "{'0_word_acc': 0.9448, '0_word_acc_ignore_case': 0.9448, '0_word_acc_ignore_case_symbol': 0.9816, '0_char_recall': 0.9985, '0_char_precision': 0.9956, '0_1-N.E.D': 0.9902}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {finetuned_model_89img_6ep} --eval acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-66d3b219",
   "language": "python",
   "display_name": "open mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}