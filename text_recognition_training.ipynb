{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "dataset i√ßin: configs/_base_/recog_datasets/toy_data.py\n",
    "\n",
    "anno file format:\n",
    "```\n",
    "1223731.jpg GRAND\n",
    "1223733.jpg HOTEL\n",
    "1223732.jpg HOTEL\n",
    "1223729.jpg PACIFIC\n",
    "1036169.jpg 03/09/2009\n",
    "1190237.jpg ANING\n",
    "1058891.jpg Virgin\n",
    "1058892.jpg america\n",
    "1240078.jpg ATTACK\n",
    "1210236.jpg DAVIDSON\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "root = 'tests/data/ocr_toy_dataset'\n",
    "img_prefix = f'{root}/imgs'\n",
    "train_anno_file1 = f'{root}/label.txt'\n",
    "\n",
    "train1 = dict(\n",
    "    type=dataset_type,\n",
    "    img_prefix=img_prefix,\n",
    "    ann_file=train_anno_file1,\n",
    "    loader=dict(\n",
    "        type='HardDiskLoader',\n",
    "        repeat=100,\n",
    "        parser=dict(\n",
    "            type='LineStrParser',\n",
    "            keys=['filename', 'text'],\n",
    "            keys_idx=[0, 1],\n",
    "            separator=' ')),\n",
    "    pipeline=None,\n",
    "    test_mode=False)\n",
    "```\n",
    "\n",
    "eval metrics\n",
    "\n",
    "```\n",
    "\n",
    "         eval_res (dict[str: float]): Metric dict for text recognition, include:\n",
    "             - word_acc: Accuracy in word level.\n",
    "             - word_acc_ignore_case: Accuracy in word level, ignore letter case.\n",
    "             - word_acc_ignore_case_symbol: Accuracy in word level, ignore\n",
    "                 letter case and symbol. (default metric for\n",
    "                 academic evaluation)\n",
    "             - char_recall: Recall in character level, ignore\n",
    "                 letter case and symbol.\n",
    "             - char_precision: Precision in character level, ignore\n",
    "                 letter case and symbol.\n",
    "             - 1-N.E.D: 1 - normalized_edit_distance. \n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "master_ckpt = \"/home/gsoykan20/.cache/torch/checkpoints/master_r31_12e_ST_MJ_SA-787edd36.pth\"\n",
    "master_config = \"/home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/master/master_custom_dataset.py\"\n",
    "master_216 = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/master_custom_dataset_216_40/best_0_char_precision_epoch_3.pth\"\n",
    "master_254 = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/master_custom_dataset_254_40/best_0_char_precision_epoch_4.pth\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tools/train.py /home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/master/master_custom_dataset.py --load-from /home/gsoykan20/.cache/torch/checkpoints/master_r31_12e_ST_MJ_SA-787edd36.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'python tools/train.py {master_config} --load-from {master_ckpt}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tools/test.py /home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/master/master_custom_dataset.py /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/master_custom_dataset_254_40/best_0_char_precision_epoch_4.pth --eval acc\n"
     ]
    }
   ],
   "source": [
    "print(f'python tools/test.py {master_config} {master_254} --eval acc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#TODO: evaluate as it is right now with all metric\n",
    "#      0_word_acc: 0.0448, 0_word_acc_ignore_case: 0.0448, 0_word_acc_ignore_case_symbol: 0.0448, 0_char_recall: 0.1769, 0_char_precision: 0.2884, 0_1-N.E.D: 0.1454\n",
    "\n",
    "model_config_path_ref = \"/home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/nrtr/nrtr_r31_1by8_1by4_custom.py\"\n",
    "\n",
    "model_checkpoint_file = \"/home/gsoykan20/.cache/torch/hub/checkpoints/nrtr_r31_1by8_1by4_academic_20211123-e1fdb322.pth\"\n",
    "\n",
    "finetuned_model_51img_20ep = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom_20epoch_51img/best_0_1-N.E.D_epoch_10.pth\"\n",
    "\n",
    "finetuned_model_89img_6ep = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom/best_0_char_precision_epoch_3.pth\"\n",
    "finetuned_model_156img_6ep = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom_156_6ep/best_0_char_precision_epoch_3.pth\"\n",
    "finetuned_model_246img_6ep = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom_256_6ep/best_0_char_precision_epoch_4.pth\"\n",
    "\n",
    "finetuned_model_254_40 = \"/home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom_254_40/best_0_char_precision_epoch_2.pth\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tools/train.py /home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/nrtr/nrtr_r31_1by8_1by4_custom.py --load-from /home/gsoykan20/.cache/torch/hub/checkpoints/nrtr_r31_1by8_1by4_academic_20211123-e1fdb322.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'python tools/train.py {model_config_path_ref} --load-from {model_checkpoint_file}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "2022-06-04 16:30:59,285 - mmocr - INFO - Environment info:\r\n",
      "------------------------------------------------------------\r\n",
      "sys.platform: linux\r\n",
      "Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]\r\n",
      "CUDA available: True\r\n",
      "GPU 0: Quadro RTX 3000\r\n",
      "CUDA_HOME: /usr/local/cuda\r\n",
      "NVCC: Build cuda_11.4.r11.4/compiler.30300941_0\r\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\n",
      "PyTorch: 1.6.0\r\n",
      "PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 7.3\r\n",
      "  - C++ Version: 201402\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 10.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n",
      "  - CuDNN 7.6.3\r\n",
      "  - Magma 2.5.2\r\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \r\n",
      "\r\n",
      "TorchVision: 0.7.0\r\n",
      "OpenCV: 4.5.4\r\n",
      "MMCV: 1.3.17\r\n",
      "MMCV Compiler: GCC 7.3\r\n",
      "MMCV CUDA Compiler: 10.1\r\n",
      "MMOCR: 0.4.1+e430935\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "2022-06-04 16:31:00,124 - mmocr - INFO - Distributed training: False\r\n",
      "2022-06-04 16:31:00,938 - mmocr - INFO - Config:\r\n",
      "checkpoint_config = dict(interval=100, metric='acc')\r\n",
      "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\r\n",
      "dist_params = dict(backend='nccl')\r\n",
      "log_level = 'INFO'\r\n",
      "load_from = '/home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/nrtr/nrtr_r31_1by8_1by4_custom.py'\r\n",
      "resume_from = None\r\n",
      "workflow = [('train', 1)]\r\n",
      "opencv_num_threads = 0\r\n",
      "mp_start_method = 'fork'\r\n",
      "optimizer = dict(type='Adam', lr=0.0001)\r\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=0.5))\r\n",
      "lr_config = dict(policy='step', step=[3, 4])\r\n",
      "total_epochs = 6\r\n",
      "img_norm_cfg = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='ResizeOCR',\r\n",
      "        height=32,\r\n",
      "        min_width=32,\r\n",
      "        max_width=160,\r\n",
      "        keep_aspect_ratio=True,\r\n",
      "        width_downsample_ratio=0.25),\r\n",
      "    dict(type='ToTensorOCR'),\r\n",
      "    dict(\r\n",
      "        type='NormalizeOCR',\r\n",
      "        mean=[0.485, 0.456, 0.406],\r\n",
      "        std=[0.229, 0.224, 0.225]),\r\n",
      "    dict(\r\n",
      "        type='Collect',\r\n",
      "        keys=['img'],\r\n",
      "        meta_keys=[\r\n",
      "            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'\r\n",
      "        ])\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='ResizeOCR',\r\n",
      "        height=32,\r\n",
      "        min_width=32,\r\n",
      "        max_width=160,\r\n",
      "        keep_aspect_ratio=True),\r\n",
      "    dict(type='ToTensorOCR'),\r\n",
      "    dict(\r\n",
      "        type='NormalizeOCR',\r\n",
      "        mean=[0.485, 0.456, 0.406],\r\n",
      "        std=[0.229, 0.224, 0.225]),\r\n",
      "    dict(\r\n",
      "        type='Collect',\r\n",
      "        keys=['img'],\r\n",
      "        meta_keys=[\r\n",
      "            'filename', 'ori_shape', 'resize_shape', 'valid_ratio',\r\n",
      "            'img_norm_cfg', 'ori_filename', 'img_shape'\r\n",
      "        ])\r\n",
      "]\r\n",
      "dataset_type = 'OCRDataset'\r\n",
      "root = 'tests/data/ocr_comics_speech_bubble_dataset'\r\n",
      "train_img_prefix = 'tests/data/ocr_comics_speech_bubble_dataset/train/imgs'\r\n",
      "train_anno_file1 = 'tests/data/ocr_comics_speech_bubble_dataset/train/label.txt'\r\n",
      "test_img_prefix = 'tests/data/ocr_comics_speech_bubble_dataset/test/imgs'\r\n",
      "test_anno_file1 = 'tests/data/ocr_comics_speech_bubble_dataset/test/label.txt'\r\n",
      "train = dict(\r\n",
      "    type='OCRDataset',\r\n",
      "    img_prefix='tests/data/ocr_comics_speech_bubble_dataset/train/imgs',\r\n",
      "    ann_file='tests/data/ocr_comics_speech_bubble_dataset/train/label.txt',\r\n",
      "    loader=dict(\r\n",
      "        type='HardDiskLoader',\r\n",
      "        repeat=1,\r\n",
      "        parser=dict(\r\n",
      "            type='LineStrParser',\r\n",
      "            keys=['filename', 'text'],\r\n",
      "            keys_idx=[0, 1],\r\n",
      "            separator=' ')),\r\n",
      "    pipeline=None,\r\n",
      "    test_mode=False)\r\n",
      "test = dict(\r\n",
      "    type='OCRDataset',\r\n",
      "    img_prefix='tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "    ann_file='tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "    loader=dict(\r\n",
      "        type='HardDiskLoader',\r\n",
      "        repeat=1,\r\n",
      "        parser=dict(\r\n",
      "            type='LineStrParser',\r\n",
      "            keys=['filename', 'text'],\r\n",
      "            keys_idx=[0, 1],\r\n",
      "            separator=' ')),\r\n",
      "    pipeline=None,\r\n",
      "    test_mode=True)\r\n",
      "train_list = [\r\n",
      "    dict(\r\n",
      "        type='OCRDataset',\r\n",
      "        img_prefix='tests/data/ocr_comics_speech_bubble_dataset/train/imgs',\r\n",
      "        ann_file='tests/data/ocr_comics_speech_bubble_dataset/train/label.txt',\r\n",
      "        loader=dict(\r\n",
      "            type='HardDiskLoader',\r\n",
      "            repeat=1,\r\n",
      "            parser=dict(\r\n",
      "                type='LineStrParser',\r\n",
      "                keys=['filename', 'text'],\r\n",
      "                keys_idx=[0, 1],\r\n",
      "                separator=' ')),\r\n",
      "        pipeline=None,\r\n",
      "        test_mode=False)\r\n",
      "]\r\n",
      "test_list = [\r\n",
      "    dict(\r\n",
      "        type='OCRDataset',\r\n",
      "        img_prefix='tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "        ann_file='tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "        loader=dict(\r\n",
      "            type='HardDiskLoader',\r\n",
      "            repeat=1,\r\n",
      "            parser=dict(\r\n",
      "                type='LineStrParser',\r\n",
      "                keys=['filename', 'text'],\r\n",
      "                keys_idx=[0, 1],\r\n",
      "                separator=' ')),\r\n",
      "        pipeline=None,\r\n",
      "        test_mode=True)\r\n",
      "]\r\n",
      "label_convertor = dict(\r\n",
      "    type='AttnConvertor', dict_type='DICT90', with_unknown=True)\r\n",
      "model = dict(\r\n",
      "    type='NRTR',\r\n",
      "    backbone=dict(\r\n",
      "        type='ResNet31OCR',\r\n",
      "        layers=[1, 2, 5, 3],\r\n",
      "        channels=[32, 64, 128, 256, 512, 512],\r\n",
      "        stage4_pool_cfg=dict(kernel_size=(2, 1), stride=(2, 1)),\r\n",
      "        last_stage_pool=False),\r\n",
      "    encoder=dict(type='NRTREncoder'),\r\n",
      "    decoder=dict(type='NRTRDecoder'),\r\n",
      "    loss=dict(type='TFLoss'),\r\n",
      "    label_convertor=dict(\r\n",
      "        type='AttnConvertor', dict_type='DICT90', with_unknown=True),\r\n",
      "    max_seq_len=40)\r\n",
      "data = dict(\r\n",
      "    samples_per_gpu=32,\r\n",
      "    workers_per_gpu=4,\r\n",
      "    train=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='OCRDataset',\r\n",
      "                img_prefix=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/train/imgs',\r\n",
      "                ann_file=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/train/label.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineStrParser',\r\n",
      "                        keys=['filename', 'text'],\r\n",
      "                        keys_idx=[0, 1],\r\n",
      "                        separator=' ')),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=False)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='ResizeOCR',\r\n",
      "                height=32,\r\n",
      "                min_width=32,\r\n",
      "                max_width=160,\r\n",
      "                keep_aspect_ratio=True,\r\n",
      "                width_downsample_ratio=0.25),\r\n",
      "            dict(type='ToTensorOCR'),\r\n",
      "            dict(\r\n",
      "                type='NormalizeOCR',\r\n",
      "                mean=[0.485, 0.456, 0.406],\r\n",
      "                std=[0.229, 0.224, 0.225]),\r\n",
      "            dict(\r\n",
      "                type='Collect',\r\n",
      "                keys=['img'],\r\n",
      "                meta_keys=[\r\n",
      "                    'filename', 'ori_shape', 'resize_shape', 'text',\r\n",
      "                    'valid_ratio'\r\n",
      "                ])\r\n",
      "        ]),\r\n",
      "    val=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='OCRDataset',\r\n",
      "                img_prefix=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "                ann_file=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineStrParser',\r\n",
      "                        keys=['filename', 'text'],\r\n",
      "                        keys_idx=[0, 1],\r\n",
      "                        separator=' ')),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=True)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='ResizeOCR',\r\n",
      "                height=32,\r\n",
      "                min_width=32,\r\n",
      "                max_width=160,\r\n",
      "                keep_aspect_ratio=True),\r\n",
      "            dict(type='ToTensorOCR'),\r\n",
      "            dict(\r\n",
      "                type='NormalizeOCR',\r\n",
      "                mean=[0.485, 0.456, 0.406],\r\n",
      "                std=[0.229, 0.224, 0.225]),\r\n",
      "            dict(\r\n",
      "                type='Collect',\r\n",
      "                keys=['img'],\r\n",
      "                meta_keys=[\r\n",
      "                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio',\r\n",
      "                    'img_norm_cfg', 'ori_filename', 'img_shape'\r\n",
      "                ])\r\n",
      "        ]),\r\n",
      "    test=dict(\r\n",
      "        type='UniformConcatDataset',\r\n",
      "        datasets=[\r\n",
      "            dict(\r\n",
      "                type='OCRDataset',\r\n",
      "                img_prefix=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/imgs',\r\n",
      "                ann_file=\r\n",
      "                'tests/data/ocr_comics_speech_bubble_dataset/test/label.txt',\r\n",
      "                loader=dict(\r\n",
      "                    type='HardDiskLoader',\r\n",
      "                    repeat=1,\r\n",
      "                    parser=dict(\r\n",
      "                        type='LineStrParser',\r\n",
      "                        keys=['filename', 'text'],\r\n",
      "                        keys_idx=[0, 1],\r\n",
      "                        separator=' ')),\r\n",
      "                pipeline=None,\r\n",
      "                test_mode=True)\r\n",
      "        ],\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='ResizeOCR',\r\n",
      "                height=32,\r\n",
      "                min_width=32,\r\n",
      "                max_width=160,\r\n",
      "                keep_aspect_ratio=True),\r\n",
      "            dict(type='ToTensorOCR'),\r\n",
      "            dict(\r\n",
      "                type='NormalizeOCR',\r\n",
      "                mean=[0.485, 0.456, 0.406],\r\n",
      "                std=[0.229, 0.224, 0.225]),\r\n",
      "            dict(\r\n",
      "                type='Collect',\r\n",
      "                keys=['img'],\r\n",
      "                meta_keys=[\r\n",
      "                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio',\r\n",
      "                    'img_norm_cfg', 'ori_filename', 'img_shape'\r\n",
      "                ])\r\n",
      "        ]))\r\n",
      "evaluation = dict(\r\n",
      "    interval=1, metric=['acc'], save_best='0_char_precision', rule='greater')\r\n",
      "work_dir = './work_dirs/nrtr_r31_1by8_1by4_custom'\r\n",
      "gpu_ids = [0]\r\n",
      "\r\n",
      "2022-06-04 16:31:00,947 - mmocr - INFO - Set random seed to 605525881, deterministic: False\r\n",
      "2022-06-04 16:31:01,351 - mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"tools/train.py\", line 224, in <module>\r\n",
      "    main()\r\n",
      "  File \"tools/train.py\", line 220, in main\r\n",
      "    meta=meta)\r\n",
      "  File \"/home/gsoykan20/Desktop/self_development/mmocr/mmocr/apis/train.py\", line 74, in train_detector\r\n",
      "    model = MMDataParallel(model, device_ids=cfg.gpu_ids)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/parallel/data_parallel.py\", line 27, in __init__\r\n",
      "    super(MMDataParallel, self).__init__(*args, dim=dim, **kwargs)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 139, in __init__\r\n",
      "    self.module.cuda(device_ids[0])\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 458, in cuda\r\n",
      "    return self._apply(lambda t: t.cuda(device))\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 354, in _apply\r\n",
      "    module._apply(fn)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 354, in _apply\r\n",
      "    module._apply(fn)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 376, in _apply\r\n",
      "    param_applied = fn(param)\r\n",
      "  File \"/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 458, in <lambda>\r\n",
      "    return self._apply(lambda t: t.cuda(device))\r\n",
      "RuntimeError: CUDA error: out of memory\r\n"
     ]
    }
   ],
   "source": [
    "# --load-from\n",
    "!python tools/train.py {model_config_path_ref} --load-from {model_checkpoint_file}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing\n",
    "\n",
    "python tools/test.py {model_config_path_ref} {model_checkpoint_file} --eval acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tools/test.py /home/gsoykan20/Desktop/self_development/mmocr/configs/textrecog/nrtr/nrtr_r31_1by8_1by4_custom.py /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom_254_40/best_0_char_precision_epoch_2.pth --eval acc\n"
     ]
    }
   ],
   "source": [
    "print(f'python tools/test.py {model_config_path_ref} {finetuned_model_254_40} --eval acc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "load checkpoint from local path: /home/gsoykan20/.cache/torch/hub/checkpoints/nrtr_r31_1by8_1by4_academic_20211123-e1fdb322.pth\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 163/163, 27.0 task/s, elapsed: 6s, ETA:     0s\r\n",
      "Evaluateing tests/data/ocr_comics_speech_bubble_dataset/test/label.txt with 163 images now\r\n",
      "{'0_word_acc': 0.2454, '0_word_acc_ignore_case': 0.8957, '0_word_acc_ignore_case_symbol': 0.9509, '0_char_recall': 0.9942, '0_char_precision': 0.9827, '0_1-N.E.D': 0.9716}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {model_checkpoint_file} --eval acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:33: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting OMP_NUM_THREADS environment variable for each process '\r\n",
      "/home/gsoykan20/Desktop/self_development/mmocr/mmocr/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  f'Setting MKL_NUM_THREADS environment variable for each process '\r\n",
      "load checkpoint from local path: /home/gsoykan20/Desktop/self_development/mmocr/work_dirs/nrtr_r31_1by8_1by4_custom/best_0_char_precision_epoch_3.pth\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 163/163, 26.2 task/s, elapsed: 6s, ETA:     0s\r\n",
      "Evaluateing tests/data/ocr_comics_speech_bubble_dataset/test/label.txt with 163 images now\r\n",
      "{'0_word_acc': 0.9448, '0_word_acc_ignore_case': 0.9448, '0_word_acc_ignore_case_symbol': 0.9816, '0_char_recall': 0.9985, '0_char_precision': 0.9956, '0_1-N.E.D': 0.9902}\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {model_config_path_ref} {finetuned_model_89img_6ep} --eval acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-66d3b219",
   "language": "python",
   "display_name": "open mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}